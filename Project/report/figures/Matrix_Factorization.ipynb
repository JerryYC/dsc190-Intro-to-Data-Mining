{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can read the paper for more detail. <BR>\n",
    "Reference: https://ieeexplore.ieee.org/abstract/document/5197422"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Matrix_Factorization:\n",
    "    def __init__(self, alpha = 0.00001, iterations = 50, num_of_latent = 200, lam = 0.0005):\n",
    "        \"\"\"\n",
    "            Some initializations, if neccesary\n",
    "            \n",
    "            attributes: \n",
    "                        alpha: Learning Rate, default 0.01\n",
    "                        num_iter: Number of Iterations to update coefficient with training data\n",
    "                        num_of_latent: Number of latent factor.\n",
    "                        lam: Regularization constant\n",
    "                        \n",
    "            \n",
    "            TODO: 1. Initialize all variables needed.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.alpha = alpha\n",
    "        self.iterations = iterations\n",
    "        self.num_of_latent = num_of_latent\n",
    "        self.lam = lam\n",
    "        \n",
    "    def fit(self, train):\n",
    "        \"\"\"\n",
    "            Train: list of tuples with (User, Movie, Rating)\n",
    "            num_user: Number of unique user.\n",
    "            num_movie: Number of unique movie\n",
    "            \n",
    "            TODO: 2. Initialize num_user and num_movie\n",
    "                  3. Save the training set.\n",
    "                  4. Initialize P and Q matrix, with normal distribution with mean = 0. \n",
    "                  Hint: Think about what P and Q represent, what they should do.Think about the shape too. \n",
    "            \n",
    "        \n",
    "        \"\"\"\n",
    "        num_user = max(map(lambda t:t[0], train)) + 1\n",
    "        num_movie =  max(map(lambda t:t[1], train)) + 1\n",
    "        \n",
    "        self.train = train\n",
    "        \n",
    "        self.P = np.random.normal(loc = 0, size=[num_user, self.num_of_latent])\n",
    "        self.Q = np.random.normal(loc = 0, size=[num_movie, self.num_of_latent])\n",
    "        \n",
    "        rmse_lst = []\n",
    "        \n",
    "        \"\"\"\n",
    "            TODO: 5: Calculate the error, using P and Q matrix. \n",
    "                  6: We need to check if the absolute value error is less than some constant. Store the previous Q and P for adaptive learning rate.\n",
    "                      If it is less than that constant then we update P and Q matrix. \n",
    "                      (When update, update the P and Q at the same time. Think about why it is important.)\n",
    "                      Otherwise use the error to update the Q and P matrix.\n",
    "                      \n",
    "                  7: For each entry update temp_mse, and append the Current iteration RMSE to rmse_lst.\n",
    "                  \n",
    "        \"\"\"\n",
    " \n",
    "        for f in range(self.iterations):\n",
    "            ### Random Shuffle. Why is this called?\n",
    "            np.random.shuffle(self.train)\n",
    "            \n",
    "            temp_mse = 0\n",
    "\n",
    "            previous_Q = self.Q.copy()\n",
    "            previous_P = self.P.copy()\n",
    "            \n",
    "            Count = 0\n",
    "   \n",
    "            for tup in self.train:\n",
    "                u,i,rating = tup\n",
    "                error = rating - self.Q[i].T @ self.P[u]\n",
    "                \n",
    "                if abs(error) > 20 :\n",
    "                    continue\n",
    "                Count += 1\n",
    "                temp_mse += error**2\n",
    "                \n",
    "                #### Don't Modify this code, helpful for converge.\n",
    "#                 if np.isinf(self.Q).any() or np.isinf(self.P).any() or np.isnan(self.Q).any() or np.isnan(self.P).any():\n",
    "#                     pass\n",
    "#                 else:\n",
    "                    #### NEED TO MODIFY #### Update P and Q.\n",
    "                self.P[u] += 2 * self.alpha * error * self.Q[i] - self.lam * self.P[u]\n",
    "                self.Q[i] += 2 * self.alpha * error * self.P[u] - self.lam * self.Q[i]\n",
    "                \n",
    "            rmse_lst.append(temp_mse / Count)\n",
    "            print(f, rmse_lst[-1])\n",
    "            \n",
    "            \n",
    "            \"\"\"\n",
    "                TODO: 8: Implement the adaptive learning rate.\n",
    "                         If current rmse is less than previous iteration, let's increase by a factor range from 1 - 1.5\n",
    "                         Otherwise we decrease by a factor range from 0.5 - 1\n",
    "                      9: If the current rmse is greater than previous iteration.\n",
    "                         Check the relative error, (previous - current)/ previous.\n",
    "                         If it is greater than 0.1, we restore the previous Q and P. (Try without it. Think about why we need this.)\n",
    "            \"\"\"\n",
    "            if len(rmse_lst)==1 or rmse_lst[-1]<rmse_lst[-2]:\n",
    "                self.alpha = self.alpha*1.25\n",
    "            else:\n",
    "                self.alpha = self.alpha*0.75\n",
    "                if (rmse_lst[-1] - rmse_lst[-2])/rmse_lst[-2] > 0.1:\n",
    "                    self.Q = previous_Q\n",
    "                    self.P = previous_P\n",
    "                    \n",
    "                \n",
    "        self.rmse = rmse_lst\n",
    "        \n",
    "    def ind_predict(self, tup):\n",
    "        \"\"\"\n",
    "            tup: One single entry, (user, movie)\n",
    "            \n",
    "            TODO: 10: Use P and Q to make prediction on single entry.\n",
    "            \n",
    "        \"\"\"\n",
    "        u,i = tup\n",
    "        \n",
    "        return self.Q[i].T @ self.P[u]\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "            X: list of entries\n",
    "            \n",
    "            TODO: 11: Use ind_predict we create to make predicitons.\n",
    "        \"\"\"\n",
    "        res = []\n",
    "        for i in X:\n",
    "            res.append(self.ind_predict(i))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('./ratings.csv')\n",
    "ratings = ratings.sort_values('timestamp').reset_index(drop = True).astype(int)\n",
    "a = np.sort(ratings.movieId.unique())\n",
    "index_dict = {}\n",
    "for i in range(len(a)):\n",
    "    index_dict[a[i]]  = i\n",
    "ratings.movieId = ratings.movieId.apply(lambda x: index_dict[x]) \n",
    "\n",
    "grouped_userId = list(ratings.groupby(['userId']).apply(lambda x: x[['movieId','rating']].values))\n",
    "grouped_movieId = list(ratings.groupby(['movieId']).apply(lambda x: x[['userId','rating']].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "train = set()\n",
    "test = set()\n",
    "\n",
    "for i in range(len(grouped_movieId)):\n",
    "    temp_len = len(grouped_movieId[i])\n",
    "    for j in range(temp_len):\n",
    "        if j < temp_len * 0.8:\n",
    "            train.add((grouped_movieId[i][j][0]-1,i - 1, grouped_movieId[i][j][1]))\n",
    "        else:\n",
    "            test.add((grouped_movieId[i][j][0] -1, i - 1,grouped_movieId[i][j][1]))\n",
    "train = list(train)\n",
    "test = list(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84071, 16765)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try to understand what is done for data cleaning. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If you are doing things correctly (with tuning), you will get something lower than 1.1 test RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 86.48621568136389\n",
      "1 60.23648236911481\n",
      "2 46.22261163974643\n",
      "3 37.41356128338474\n",
      "4 31.210382677873717\n",
      "5 26.826540482113412\n",
      "6 23.551035154807597\n",
      "7 20.98983135060455\n",
      "8 18.99522337325284\n",
      "9 17.420100649192683\n",
      "10 16.109918624348058\n",
      "11 15.016548357447942\n",
      "12 14.09967332435114\n",
      "13 13.313424753789674\n",
      "14 12.645811547942074\n",
      "15 12.032159876336042\n",
      "16 11.457702862514447\n",
      "17 10.907553731515899\n",
      "18 10.383743274381247\n",
      "19 9.75031096030124\n",
      "20 8.85774601446156\n",
      "21 7.471321605818507\n",
      "22 5.700545633486387\n",
      "23 4.232672060316316\n",
      "24 3.314123208867258\n",
      "25 2.777918932322361\n",
      "26 2.496243262493866\n",
      "27 2.3611443110053454\n",
      "28 2.4706523573931922\n",
      "29 1.6377822780776694\n",
      "30 1.5369443212159497\n",
      "31 2.0725272581261507\n",
      "32 1.2974535175593742\n",
      "33 1.5302625351435895\n",
      "34 1.054098038276624\n",
      "35 1.1846876156305588\n",
      "36 0.8932719117635987\n",
      "37 0.9900178661424461\n",
      "38 0.8130132408020676\n",
      "39 0.8644259807231988\n",
      "40 0.6903700281042745\n",
      "41 0.7027488237180819\n",
      "42 0.6135487474409538\n",
      "43 0.6055089383392284\n",
      "44 0.6523452943648825\n",
      "45 0.5432557252094005\n",
      "46 0.5506856905643113\n",
      "47 0.4821227880874611\n",
      "48 0.4855264732516955\n",
      "49 0.44661640692460425\n",
      "50 0.45469918689337213\n",
      "51 0.42487062339208914\n",
      "52 0.42075370956551567\n",
      "53 0.4278439885116859\n",
      "54 0.39406770998137575\n",
      "55 0.3917444245783014\n",
      "56 0.4218121376812821\n",
      "57 0.3787191713243529\n",
      "58 0.38049669494919847\n",
      "59 0.34199692952234323\n",
      "60 0.3433167136153058\n",
      "61 0.3282349938704383\n",
      "62 0.3280188426591298\n",
      "63 0.3362016119558484\n",
      "64 0.31887042078190614\n",
      "65 0.31925198863089443\n",
      "66 0.3033371284268703\n",
      "67 0.2973557919858739\n",
      "68 0.31351610491205445\n",
      "69 0.2893025750402952\n",
      "70 0.29196699456399994\n",
      "71 0.27548120793104297\n",
      "72 0.27807897037989027\n",
      "73 0.27406533369583913\n",
      "74 0.2788566886698801\n",
      "75 0.2661980171745658\n",
      "76 0.2782219924114525\n",
      "77 0.2668206456370237\n",
      "78 0.27651545127754334\n",
      "79 0.27581172250148167\n",
      "80 0.28013343574851074\n",
      "81 0.29963158634326353\n",
      "82 0.3158861411069969\n",
      "83 0.3649386829233305\n",
      "84 0.40527323612312793\n",
      "85 0.45663001977150686\n",
      "86 0.519917832799843\n",
      "87 0.5971450369056248\n",
      "88 0.6838134433493949\n",
      "89 0.7724796928926553\n",
      "90 0.8643650362519554\n",
      "91 0.9482038060712589\n",
      "92 2.102859917174911\n",
      "93 2.2587490338697145\n",
      "94 3.46039294064396\n",
      "95 3.600081626844663\n",
      "96 4.838527358541391\n",
      "97 4.94113318352108\n",
      "98 6.093852021343892\n",
      "99 6.161388584827758\n"
     ]
    }
   ],
   "source": [
    "clf = Matrix_Factorization(alpha = 0.00001, iterations = 100, num_of_latent = 200, lam = 0.001)\n",
    "clf.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "error = 0\n",
    "pred = clf.predict(map(lambda t: (t[0],t[1]),test))\n",
    "for i in range(len(test)):\n",
    "    error += (test[i][2] - pred[i])**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.770206121665545"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(error/ len(test))** (0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Matrix_Factorization_with_bias:\n",
    "    def __init__(self, alpha = 0.00001, iterations = 50, num_of_latent = 200, lam = 0.01):\n",
    "        \n",
    "        \"\"\"\n",
    "            Some initializations, if neccesary\n",
    "            \n",
    "            attributes: \n",
    "                        alpha: Learning Rate, default 0.01\n",
    "                        num_iter: Number of Iterations to update coefficient with training data\n",
    "                        num_of_latent: Number of latent factor.\n",
    "                        lam: Regularization constant\n",
    " \n",
    "            \n",
    "            TODO: 1. Initialize all variables needed.\n",
    "        \"\"\"\n",
    "            \n",
    "        self.alpha = alpha\n",
    "        self.iterations = iterations\n",
    "        self.num_of_latent = num_of_latent\n",
    "        self.lam = lam\n",
    "\n",
    "\n",
    "        \n",
    "    def fit(self, train):\n",
    "        \"\"\"\n",
    "            Train: list of tuples with (User, Movie, Rating)\n",
    "            num_user: Number of unique user.\n",
    "            num_movie: Number of unique movie\n",
    "            \n",
    "            TODO: 2. Initialize num_user and num_movie.\n",
    "                  3. Save the training set.\n",
    "                  4. Initialize bu , bi and b. b is the global mean of the rating.\n",
    "                  5. Initialize P and Q matrix. \n",
    "                  Hint: Think about what P and Q represent, what they should do.Think about the shape too. \n",
    "                  \n",
    "            \n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        num_user, num_movie = train.shape\n",
    "\n",
    "        self.train = train\n",
    "        \n",
    "        self.P = [1]\n",
    "        self.Q = [1]\n",
    "        \n",
    "        self.bu = [1]\n",
    "        self.bi = [1]\n",
    "        self.b = 2 \n",
    "        \n",
    "        rmse_lst = []\n",
    "        \n",
    "        \"\"\"\n",
    "            TODO: 5: Calculate the error, using P , Q , bu , bi and b. \n",
    "                  6: Update the P , Q , bu , bi and b with error you calculate. \n",
    "                    (Think about why we don't need to check the absolute of error)\n",
    "                  7: For each entry update temp_mse, and append the Current iteration RMSE to rmse_lst.\n",
    "                  \n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        for f in range(self.iterations):\n",
    "            \n",
    "            np.random.shuffle(self.train)\n",
    "            \n",
    "            temp_mse = 0\n",
    "            previous_Q = [1]\n",
    "            previous_P = [1]\n",
    "            previous_bu = [1]\n",
    "            previous_bi = [1]\n",
    "            \n",
    "            Count = 0\n",
    "            for tup in self.train:\n",
    "                u,i,rating = tup\n",
    "                \n",
    "                error = 1\n",
    "            \n",
    "\n",
    "                Count += 1   \n",
    "                temp_mse += 1\n",
    "                \n",
    "                bu = [1]\n",
    "                bi = [1]\n",
    "                \n",
    "                temp_Q = [1]\n",
    "                \n",
    "                Q = [1]\n",
    "                P = [1]\n",
    "                \n",
    "                # You might want to update column by column\n",
    "                self.Q = Q\n",
    "                self.P = P\n",
    "                self.bu = bu\n",
    "                self.bi = bi\n",
    "            \n",
    "            rmse_lst.append(1)\n",
    "                \n",
    "            \n",
    "            \n",
    "            \"\"\"\n",
    "                TODO: 8: Implement the adaptive learning rate.\n",
    "                         If current rmse is less than previous iteration, let's increase by a factor range from 1 - 1.5\n",
    "                         Otherwise we decrease by a factor range from 0.5 - 1\n",
    "                      9: If the current rmse is greater than previous iteration.\n",
    "                         Check the relative error, (previous - current)/ previous.\n",
    "                         If it is greater than 0.1, we restore the previous Q and P. (Try without it. Think about why we need this.)\n",
    "            \"\"\"\n",
    "                \n",
    "            \n",
    "            if True:\n",
    "                self.alpha = 1\n",
    "            else:\n",
    "                self.alpha = 1\n",
    "                if True :\n",
    "                    self.Q = [1]\n",
    "                    self.P = [1]\n",
    "                    self.bu = [1]\n",
    "                    self.bi = [1]\n",
    "                    \n",
    "                    \n",
    "            \n",
    "            \n",
    "        self.rmse = rmse_lst\n",
    "            \n",
    "    def ind_predict(self, tup):\n",
    "        \"\"\"\n",
    "            tup: One single entry, (user, movie)\n",
    "            \n",
    "            TODO: 10: Use P and Q to make prediction on single entry.\n",
    "            \n",
    "        \"\"\"\n",
    "        u,i = tup\n",
    "        return 1\n",
    "\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "            X: list of entries\n",
    "            \n",
    "            TODO: 11: Use ind_predict we create to make predicitons.\n",
    "        \"\"\"\n",
    "        res = []\n",
    "        for i in X:\n",
    "            res.append(1)\n",
    "        return res\n",
    "            \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you are doing thing correctly (With tuning), you should get a Test RMSE below 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "clf = Matrix_Factorization_with_bias()\n",
    "clf.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = 0\n",
    "pred = clf.predict(test)\n",
    "for i in range(len(test)):\n",
    "    error += (test[i][2] - pred[i])**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(error/ len(test))** (0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
